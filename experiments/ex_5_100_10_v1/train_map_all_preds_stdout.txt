[11/05 20:14:47][INFO] test_net.py: 160: Test with config:
[11/05 20:14:47][INFO] test_net.py: 161: AVA:
  ANNOTATION_DIR: /srv/beegfs02/scratch/da_action/data/ava/annotations_5_100_10/
  BGR: False
  DETECTION_SCORE_THRESH: 0.8
  EXCLUSION_FILE: ava_train_excluded_timestamps_v2.2.csv
  FRAME_DIR: /srv/beegfs02/scratch/da_action/data/ava/frames/
  FRAME_LIST_DIR: /srv/beegfs02/scratch/da_action/data/ava/frame_lists_5_100_10/
  FULL_TEST_ON_VAL: True
  GROUNDTRUTH_FILE: ava_train_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['train.csv']
  TEST_PREDICT_BOX_LISTS: ['ffffff.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
DATA:
  DECODING_BACKEND: pyav
  ENSEMBLE_METHOD: sum
  INPUT_CHANNEL_NUM: [3, 3]
  INV_UNIFORM_SAMPLE: False
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 32
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 2
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 256
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_SCALES: [256, 320]
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 1
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: False
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: False
LOG_PERIOD: 10
MODEL:
  ARCH: slowfast
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  HEAD_ACT: sigmoid
  LOSS_FUNC: bce
  MODEL_NAME: SlowFast
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 5
  SINGLE_PATHWAY_ARCH: ['c2d', 'i3d', 'slow', 'x3d']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
NONLOCAL:
  GROUP: [[1, 1], [1, 1], [1, 1], [1, 1]]
  INSTANTIATION: dot_product
  LOCATION: [[[], []], [[], []], [[6, 13, 20], []], [[], []]]
  POOL: [[[2, 2, 2], [2, 2, 2]], [[2, 2, 2], [2, 2, 2]], [[2, 2, 2], [2, 2, 2]], [[2, 2, 2], [2, 2, 2]]]
NUM_GPUS: 1
NUM_SHARDS: 1
OUTPUT_DIR: /srv/beegfs02/scratch/da_action/data/output
RESNET:
  DEPTH: 101
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3, 3], [4, 4], [6, 6], [3, 3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1, 1], [1, 1], [1, 1], [2, 2]]
  SPATIAL_STRIDES: [[1, 1], [2, 2], [2, 2], [1, 1]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: True
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 4
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.1
  BASE_LR_SCALE_NUM_SHARDS: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 300
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: sgd
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 0.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 0.01
  WEIGHT_DECAY: 1e-07
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: vis_5_100_10_v1
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 1
  CHECKPOINT_FILE_PATH: /srv/beegfs02/scratch/da_action/data/output/checkpoints_5_100_10/checkpoint_epoch_00122.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 10
  NUM_SPATIAL_CROPS: 3
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: False
  BATCH_SIZE: 4
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: 
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 1
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: False
  EVAL_PERIOD: 1
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[11/05 20:14:50][INFO] checkpoint.py: 212: Loading network weights from /srv/beegfs02/scratch/da_action/data/output/checkpoints_5_100_10/checkpoint_epoch_00122.pyth.
[11/05 20:15:04][INFO] ava_helper.py:  65: Finished loading image paths from: /srv/beegfs02/scratch/da_action/data/ava/frame_lists_5_100_10/train.csv
[11/05 20:15:05][INFO] ava_helper.py: 111: Finished loading annotations from: /srv/beegfs02/scratch/da_action/data/ava/annotations_5_100_10/ffffff.csv
[11/05 20:15:05][INFO] ava_helper.py: 113: Detection threshold: 0.8
[11/05 20:15:05][INFO] ava_helper.py: 114: Number of unique boxes: 701
[11/05 20:15:05][INFO] ava_helper.py: 115: Number of annotations: 0
[11/05 20:15:05][INFO] ava_helper.py: 162: 441 keyframes used.
[11/05 20:15:05][INFO] ava_dataset.py:  90: === AVA dataset summary ===
[11/05 20:15:05][INFO] ava_dataset.py:  91: Split: test
[11/05 20:15:05][INFO] ava_dataset.py:  92: Number of videos: 42
[11/05 20:15:05][INFO] ava_dataset.py:  96: Number of frames: 1135268
[11/05 20:15:05][INFO] ava_dataset.py:  97: Number of key frames: 441
[11/05 20:15:05][INFO] ava_dataset.py:  98: Number of boxes: 701.
[11/05 20:15:05][INFO] test_net.py: 172: Testing model for 441 iterations
[11/05 20:15:10][INFO] ava_helper.py:  65: Finished loading image paths from: /srv/beegfs02/scratch/da_action/data/ava/frame_lists_5_100_10/train.csv
[11/05 20:21:29][INFO] ava_eval_helper.py: 164: Evaluating with 454 unique GT frames.
[11/05 20:21:29][INFO] ava_eval_helper.py: 166: Evaluating with 441 unique detection frames
[11/05 20:21:29][INFO] ava_eval_helper.py: 312: AVA results wrote to detections_latest.csv
[11/05 20:21:29][INFO] ava_eval_helper.py: 313: 	took 0 seconds.
[11/05 20:21:29][INFO] ava_eval_helper.py: 312: AVA results wrote to groundtruth_latest.csv
[11/05 20:21:29][INFO] ava_eval_helper.py: 313: 	took 0 seconds.
{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/bend/bow (at the waist)': 0.635224534585938,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/crawl': 0.4686581868999361,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/crouch/kneel': 0.39290788894791046,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/dance': 0.5573300104280621,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/fall down': 0.6561043123725556,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.5420449866468804}
[11/05 20:21:29][INFO] ava_eval_helper.py: 174: AVA eval done in 0.538536 seconds.
[11/05 20:21:29][INFO] logging.py:  93: json_stats: {"map": 0.54204, "mode": "test"}
