
CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


[01/03 20:12:09][INFO] test_net.py: 177: Test with config:
[01/03 20:12:09][INFO] test_net.py: 178: AVA:
  ANNOTATION_DIR: /srv/beegfs02/scratch/da_action/data/ava/annotations_10_5000_200/
  BGR: False
  DETECTION_SCORE_THRESH: 0.8
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: /srv/beegfs02/scratch/da_action/data/ava/frames/
  FRAME_LIST_DIR: /srv/beegfs02/scratch/da_action/data/ava/frame_lists_10_5000_200/
  FULL_TEST_ON_VAL: True
  GROUNDTRUTH_FILE: ava_val_v2.2.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: ava_action_list_v2.2.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_val_predicted_boxes_gt.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train_v2.2.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
DA:
  ANNOTATION_DIR: /srv/beegfs02/scratch/da_action/data/kinetics700/annotations_10_5_2/
  AUX: False
  AUX_TEST: False
  CLASSES: 0
  DATASET: da
  DETECTION_SCORE_THRESH: 0.8
  ENABLE: False
  EXCLUSION_FILE: kinetics_val_excluded_timestamps_v2.1.csv
  FRAME_DIR: /srv/beegfs02/scratch/da_action/data/kinetics700/frames/
  FRAME_LIST_DIR: /srv/beegfs02/scratch/da_action/data/kinetics700/frame_lists_10_5_2/
  FULL_TEST_ON_VAL: True
  F_CONFUSION: -1
  GROUNDTRUTH_FILE: kinetics_val_v2.1.csv
  LABEL_MAP_FILE: ava_action_list_v2.2.pbtxt
  LR_FACTOR: 10.0
  TEST_GT_BOX_LISTS: []
  TEST_LISTS: ['val.csv']
  TEST_PREDICT_BOX_LISTS: ['kinetics_val_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: []
  TRAIN_LISTS: ['train.csv']
  TRAIN_PREDICT_BOX_LISTS: ['kinetics_train_predicted_boxes.csv']
  WEIGHT_AUX: 0.5
  WEIGHT_MAIN: 0.5
DATA:
  DECODING_BACKEND: pyav
  ENSEMBLE_METHOD: sum
  INPUT_CHANNEL_NUM: [3, 3]
  INV_UNIFORM_SAMPLE: False
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 32
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 2
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 256
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_SCALES: [256, 320]
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 1
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: False
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: False
LOG_PERIOD: 10
MODEL:
  ARCH: slowfast
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  FREEZE_TO: 392
  HEAD_ACT: sigmoid
  LAST_PRE_TRAIN: 
  LOSS_FUNC: bce
  MODEL_NAME: SlowFast
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 10
  SINGLE_PATHWAY_ARCH: ['c2d', 'i3d', 'slow', 'x3d']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
NONLOCAL:
  GROUP: [[1, 1], [1, 1], [1, 1], [1, 1]]
  INSTANTIATION: dot_product
  LOCATION: [[[], []], [[], []], [[6, 13, 20], []], [[], []]]
  POOL: [[[2, 2, 2], [2, 2, 2]], [[2, 2, 2], [2, 2, 2]], [[2, 2, 2], [2, 2, 2]], [[2, 2, 2], [2, 2, 2]]]
NUM_GPUS: 1
NUM_SHARDS: 1
OUTPUT_DIR: /srv/beegfs02/scratch/da_action/data/output/ex_10_5000_200_v2
RESNET:
  DEPTH: 101
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3, 3], [4, 4], [6, 6], [3, 3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1, 1], [1, 1], [1, 1], [2, 2]]
  SPATIAL_STRIDES: [[1, 1], [2, 2], [2, 2], [1, 1]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: True
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 4
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.1
  BASE_LR_SCALE_NUM_SHARDS: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LRS: []
  LR_POLICY: cosine
  MAX_EPOCH: 300
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: sgd
  STEPS: []
  STEP_SIZE: 1
  WARMUP_EPOCHS: 0.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 0.01
  WEIGHT_DECAY: 1e-07
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: tensorboard
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 1
  CHECKPOINT_FILE_PATH: /srv/beegfs02/scratch/da_action/data/output/ex_10_5000_200_v2/checkpoints/checkpoint_epoch_00005.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  DETECTIONS_PATH: /home/sieberl/SA2020/pyslowfast/experiments/ex_10_5000_200_v2/5_ava_val_detections_latest.csv
  ENABLE: True
  GT_PATH: /home/sieberl/SA2020/pyslowfast/experiments/ex_10_5000_200_v2/5_ava_val_groundtruth_latest.csv
  NUM_ENSEMBLE_VIEWS: 10
  NUM_SPATIAL_CROPS: 3
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: False
  BATCH_SIZE: 4
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: False
  CHECKPOINT_FILE_PATH: /srv/beegfs02/scratch/da_action/data/models_pretrained/SLOWFAST_32x2_R101_50_50.pkl
  CHECKPOINT_INFLATE: False
  CHECKPOINT_PERIOD: 1
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: False
  EVAL_PERIOD: 1
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[01/03 20:12:18][INFO] checkpoint.py: 215: Loading network weights from /srv/beegfs02/scratch/da_action/data/output/ex_10_5000_200_v2/checkpoints/checkpoint_epoch_00005.pyth.
[01/03 20:12:27][INFO] ava_helper.py:  65: Finished loading image paths from: /srv/beegfs02/scratch/da_action/data/ava/frame_lists_10_5000_200/val.csv
[01/03 20:12:27][INFO] ava_helper.py: 111: Finished loading annotations from: /srv/beegfs02/scratch/da_action/data/ava/annotations_10_5000_200/ava_val_predicted_boxes_gt.csv
[01/03 20:12:27][INFO] ava_helper.py: 113: Detection threshold: 0.8
[01/03 20:12:27][INFO] ava_helper.py: 114: Number of unique boxes: 1637
[01/03 20:12:27][INFO] ava_helper.py: 115: Number of annotations: 0
[01/03 20:12:27][INFO] ava_helper.py: 162: 1356 keyframes used.
[01/03 20:12:27][INFO] ava_dataset.py:  94: === AVA dataset summary ===
[01/03 20:12:27][INFO] ava_dataset.py:  95: Split: test
[01/03 20:12:27][INFO] ava_dataset.py:  96: Number of videos: 7
[01/03 20:12:27][INFO] ava_dataset.py: 100: Number of frames: 189212
[01/03 20:12:27][INFO] ava_dataset.py: 101: Number of key frames: 1356
[01/03 20:12:27][INFO] ava_dataset.py: 102: Number of boxes: 1637.
[01/03 20:12:27][INFO] test_net.py: 189: Testing model for 1356 iterations
[01/03 20:12:29][INFO] ava_helper.py:  65: Finished loading image paths from: /srv/beegfs02/scratch/da_action/data/ava/frame_lists_10_5000_200/val.csv
[01/03 20:35:46][INFO] ava_eval_helper.py: 165: Evaluating with 1356 unique GT frames.
[01/03 20:35:46][INFO] ava_eval_helper.py: 167: Evaluating with 1356 unique detection frames
[01/03 20:35:46][INFO] ava_eval_helper.py: 322: AVA results wrote to /home/sieberl/SA2020/pyslowfast/experiments/ex_10_5000_200_v2/5_ava_val_detections_latest.csv
[01/03 20:35:46][INFO] ava_eval_helper.py: 323: 	took 0 seconds.
[01/03 20:35:46][INFO] ava_eval_helper.py: 322: AVA results wrote to /home/sieberl/SA2020/pyslowfast/experiments/ex_10_5000_200_v2/5_ava_val_groundtruth_latest.csv
[01/03 20:35:46][INFO] ava_eval_helper.py: 323: 	took 0 seconds.
{ 'PascalBoxes_PerformanceByCategory/AP@0.5IOU/bend/bow (at the waist)': 0.5757210340332815,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/carry/hold (an object)': 0.2894210207259131,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/lie/sleep': 0.7797626195844534,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/listen to (a person)': 0.27638008988013135,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/ride (e.g., a bike, a car, a horse)': 0.7200121226307454,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/sit': 0.5910103127162202,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/talk to (e.g., self, a person, a group)': 0.5538964904454557,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/touch (an object)': 0.2919431884917435,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/walk': 0.6357197951248937,
  'PascalBoxes_PerformanceByCategory/AP@0.5IOU/watch (a person)': 0.21188739867991527,
  'PascalBoxes_Precision/mAP@0.5IOU': 0.49257540723127524}
[01/03 20:35:52][INFO] ava_eval_helper.py: 182: AVA eval done in 6.575628 seconds.
[01/03 20:35:52][INFO] logging.py:  97: json_stats: {
  "map": 0.49258,
  "mode": "test"
}
